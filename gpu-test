#!/bin/bash
#
# GPU Cluster Test - Universal CLI Tool
#
# A unified command-line interface for GPU cluster validation.
# All output is displayed in real-time - no need to check log files.
#
# Usage: ./gpu-test <command> [options]
#
# Commands:
#   validate    Run cluster validation test (distributed training)
#   nccl        Run NCCL communication test
#   import      Import custom Docker image from GHCR
#   help        Show this help message
#
# Options:
#   --nodes N              Number of nodes (default: 2)
#   --gpus-per-node N      GPUs per node (default: 8)
#   --epochs N             Training epochs (default: 5)
#   --batch-size N         Batch size per GPU (default: 64)
#   --interactive          Run interactively (Slurm only)
#   --dry-run              Test on CPU without GPU
#
# Examples:
#   ./gpu-test validate --nodes 2 --gpus-per-node 2
#   ./gpu-test nccl --nodes 4 --gpus-per-node 4
#   ./gpu-test validate --nodes 1 --gpus-per-node 1 --interactive
#   ./gpu-test validate --dry-run
#

set -euo pipefail

# Get script directory
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
cd "$SCRIPT_DIR"

# Colors disabled for better compatibility
RED=''
GREEN=''
YELLOW=''
BLUE=''
NC=''

# Default configuration
COMMAND=""
NODES=2
GPUS_PER_NODE=8
EPOCHS=5
BATCH_SIZE=64
INTERACTIVE=false
DRY_RUN=false

# Parse command
if [ $# -eq 0 ]; then
    COMMAND="help"
else
    COMMAND="$1"
    shift
fi

# Parse options
while [[ $# -gt 0 ]]; do
    case $1 in
        --nodes)
            NODES="$2"
            shift 2
            ;;
        --gpus-per-node)
            GPUS_PER_NODE="$2"
            shift 2
            ;;
        --epochs)
            EPOCHS="$2"
            shift 2
            ;;
        --batch-size)
            BATCH_SIZE="$2"
            shift 2
            ;;
        -i|--interactive)
            INTERACTIVE=true
            shift
            ;;
        --dry-run)
            DRY_RUN=true
            shift
            ;;
        --help|-h)
            COMMAND="help"
            shift
            ;;
        *)
            echo "Error: Unknown option: $1"
            echo "Use './gpu-test help' for usage information"
            exit 1
            ;;
    esac
done

# Help function
show_help() {
    cat << EOF
================================================================================
GPU Cluster Test - Universal CLI Tool
================================================================================

A unified command-line interface for GPU cluster validation.
All output is displayed in real-time - no need to check log files.

USAGE:
  ./gpu-test <command> [options]

COMMANDS:
  validate    Run cluster validation test (distributed training)
  nccl        Run NCCL communication test
  import      Import custom Docker image from GHCR
  help        Show this help message

OPTIONS:
  --nodes N              Number of nodes (default: 2)
  --gpus-per-node N      GPUs per node (default: 8)
  --epochs N             Training epochs (default: 5)
  --batch-size N         Batch size per GPU (default: 64)
  -i, --interactive      Run interactively with real-time output (validate only)
  --dry-run              Test on CPU without GPU

EXAMPLES:
  # Small cluster test (4 GPUs)
  ./gpu-test validate --nodes 2 --gpus-per-node 2

  # Medium cluster test (16 GPUs)
  ./gpu-test validate --nodes 4 --gpus-per-node 4 --epochs 10

  # NCCL communication test
  ./gpu-test nccl --nodes 2 --gpus-per-node 2

  # Interactive mode (see output in real-time)
  ./gpu-test validate --nodes 2 --gpus-per-node 2 -i

  # CPU dry-run (no GPU needed)
  ./gpu-test validate --dry-run

  # Import custom Docker image
  ./gpu-test import

ENVIRONMENT DETECTION:
  The tool automatically detects your environment:
  - Slurm: Uses srun/sbatch
  - Kubernetes: Uses kubectl/PyTorchJob
  - Standalone: Uses torchrun directly

OUTPUT:
  All output is displayed in real-time. No need to check log files.
  For batch jobs, logs are also saved to: logs/<test>_<job_id>.out

================================================================================
EOF
}

# Detect environment
detect_environment() {
    if command -v sbatch &> /dev/null; then
        echo "slurm"
    elif command -v kubectl &> /dev/null && kubectl cluster-info &> /dev/null 2>&1; then
        echo "kubernetes"
    else
        echo "standalone"
    fi
}

# Run validation test
run_validate() {
    local env=$(detect_environment)
    local total_gpus=$((NODES * GPUS_PER_NODE))
    
    echo "=========================================="
    echo "GPU Cluster Validation Test"
    echo "=========================================="
    echo "Configuration:"
    echo "  - Nodes: $NODES"
    echo "  - GPUs per node: $GPUS_PER_NODE"
    echo "  - Total GPUs: $total_gpus"
    echo "  - Epochs: $EPOCHS"
    echo "  - Batch size: $BATCH_SIZE"
    echo "  - Environment: $env"
    echo "  - Mode: $([ "$INTERACTIVE" = true ] && echo "Interactive" || echo "Batch")"
    echo "=========================================="
    echo ""
    
    if [ "$DRY_RUN" = true ]; then
        echo "Running CPU dry-run (no GPU required)..."
        python src/train.py --dry-run --epochs "$EPOCHS"
        return $?
    fi
    
    case $env in
        slurm)
            if [ "$INTERACTIVE" = true ]; then
                echo "Running interactively with srun..."
                echo ""
                ./scripts/run_acceptance.sh \
                    --nodes "$NODES" \
                    --gpus-per-node "$GPUS_PER_NODE" \
                    --epochs "$EPOCHS" \
                    --batch-size "$BATCH_SIZE"
            else
                echo "Submitting batch job with sbatch..."
                echo ""
                NODES=$NODES GPUS_PER_NODE=$GPUS_PER_NODE EPOCHS=$EPOCHS BATCH_SIZE=$BATCH_SIZE \
                    sbatch --nodes="$NODES" --gpus-per-node="$GPUS_PER_NODE" scripts/validate_clsuter.sh
                
                echo ""
                echo "Job submitted. Monitor with:"
                echo "  squeue -u \$USER"
                echo "  tail -f logs/acceptance_*.out"
            fi
            ;;
        kubernetes)
            echo "Deploying to Kubernetes..."
            echo ""
            kubectl apply -f kubernetes-example.yaml
            echo ""
            echo "Monitor with:"
            echo "  kubectl get pytorchjobs"
            echo "  kubectl logs -f <pod-name>"
            ;;
        standalone)
            echo "Running with torchrun..."
            echo ""
            torchrun \
                --nnodes="$NODES" \
                --nproc_per_node="$GPUS_PER_NODE" \
                src/train.py --epochs "$EPOCHS" --batch-size "$BATCH_SIZE"
            ;;
    esac
}

# Run NCCL test
run_nccl() {
    local env=$(detect_environment)
    local total_gpus=$((NODES * GPUS_PER_NODE))
    
    echo "=========================================="
    echo "NCCL Communication Test"
    echo "=========================================="
    echo "Configuration:"
    echo "  - Nodes: $NODES"
    echo "  - GPUs per node: $GPUS_PER_NODE"
    echo "  - Total GPUs: $total_gpus"
    echo "  - Environment: $env"
    echo "  - Mode: $([ "$INTERACTIVE" = true ] && echo "Interactive" || echo "Batch")"
    echo "=========================================="
    echo ""
    
    case $env in
        slurm)
            if [ "$INTERACTIVE" = true ]; then
                echo "Note: Interactive mode for NCCL test is not recommended for multi-node."
                echo "      Use batch mode instead: ./gpu-test nccl --nodes $NODES --gpus-per-node $GPUS_PER_NODE"
                echo ""
                echo "Submitting as batch job..."
                echo ""
            fi
            
            # Always use batch mode for NCCL multi-node tests
            NODES=$NODES GPUS_PER_NODE=$GPUS_PER_NODE \
                sbatch --nodes="$NODES" --gpus-per-node="$GPUS_PER_NODE" scripts/nccl_test.sh
            
            echo ""
            echo "Job submitted. Monitor with:"
            echo "  squeue -u \$USER"
            echo "  tail -f logs/nccl_*.out"
            ;;
        kubernetes)
            echo "Note: NCCL test for Kubernetes not yet implemented"
            echo "Use: kubectl apply -f kubernetes-example.yaml"
            ;;
        standalone)
            echo "Running with torchrun..."
            echo ""
            torchrun \
                --nnodes="$NODES" \
                --nproc_per_node="$GPUS_PER_NODE" \
                src/nccl_test.py
            ;;
    esac
}

# Run import
run_import() {
    echo "=========================================="
    echo "Import Custom Docker Image"
    echo "=========================================="
    echo "Importing image from GHCR..."
    echo ""
    
    if [ ! -f "scripts/import_image.sh" ]; then
        echo "Error: scripts/import_image.sh not found"
        exit 1
    fi
    
    ./scripts/import_image.sh
}

# Main command dispatcher
case $COMMAND in
    validate)
        run_validate
        ;;
    nccl)
        run_nccl
        ;;
    import)
        run_import
        ;;
    help|--help|-h)
        show_help
        ;;
    *)
        echo "Error: Unknown command: $COMMAND"
        echo ""
        echo "Available commands: validate, nccl, import, help"
        echo "Use './gpu-test help' for more information"
        exit 1
        ;;
esac
